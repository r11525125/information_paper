#!/usr/bin/env python3
"""
å…¬å¹³çš„KITTIå¯¦é©—ï¼šä½¿ç”¨æ‰€æœ‰å ´æ™¯çš„ä»£è¡¨æ€§æ¨£æœ¬é€²è¡ŒTSNå’ŒIPFSæ¸¬è©¦
Fair KITTI experiment with representative samples from all scenes
"""

import os
import subprocess
import pandas as pd
import numpy as np
import time
import json
from datetime import datetime

def run_fair_experiment():
    """é‹è¡Œå…¬å¹³çš„å¯¦é©— - æ¯å€‹å ´æ™¯éƒ½æ¸¬è©¦"""
    print("ğŸš€ å…¬å¹³çš„KITTIå¯¦é©— - æ‰€æœ‰å ´æ™¯")
    print("="*60)

    start_time = time.time()

    # KITTIæ•¸æ“šçµ±è¨ˆï¼ˆåŸºæ–¼å¯¦éš›æƒæï¼‰
    dataset_stats = {
        'campus': {'files': 186, 'size_gb': 0.34},
        'city': {'files': 108, 'size_gb': 0.20},
        'person': {'files': 68, 'size_gb': 0.13},
        'residential': {'files': 481, 'size_gb': 0.89},
        'road': {'files': 297, 'size_gb': 0.53}
    }

    total_files = sum(s['files'] for s in dataset_stats.values())
    total_size_gb = sum(s['size_gb'] for s in dataset_stats.values())

    print(f"æ•¸æ“šé›†è¦æ¨¡: {total_files} æª”æ¡ˆ, {total_size_gb:.2f} GB")
    print(f"å ´æ™¯: {', '.join(dataset_stats.keys())}\n")

    venv_path = "/home/adlink/å®‡ç¿°è«–æ–‡/.venv"

    # 1. å£“ç¸®å¯¦é©— - æ¯å€‹å ´æ™¯æ¸¬è©¦3å€‹æª”æ¡ˆ
    print("=== éšæ®µ1: å£“ç¸®å¯¦é©— ===")
    all_compression_results = []

    for scene, stats in dataset_stats.items():
        print(f"\nè™•ç† {scene} (å…±{stats['files']}æª”æ¡ˆ)...")

        scene_dir = f"/home/adlink/ä¸‹è¼‰/KITTI/KITTI/{scene}"
        output_csv = f"/home/adlink/å®‡ç¿°è«–æ–‡/outputs/fair_{scene}_compression.csv"

        # æ¯å€‹å ´æ™¯æ¸¬è©¦3å€‹æª”æ¡ˆï¼ŒBEå€¼1.0
        cmd = [
            "bash", "-c",
            f"source {venv_path}/bin/activate && python /home/adlink/å®‡ç¿°è«–æ–‡/scripts/run_subset_experiments.py "
            f"--data-dir {scene_dir} --max-files 3 --be-list 1.0 "
            f"--out-csv {output_csv}"
        ]

        try:
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=120)

            if result.returncode == 0 and os.path.exists(output_csv):
                df = pd.read_csv(output_csv)
                df['Scene'] = scene
                df['TotalSceneFiles'] = stats['files']
                df['TotalSceneGB'] = stats['size_gb']
                all_compression_results.append(df)
                print(f"  âœ“ æˆåŠŸ: {len(df)} ç­†å£“ç¸®è¨˜éŒ„")
            else:
                print(f"  âœ— å¤±æ•—")

        except Exception as e:
            print(f"  âœ— éŒ¯èª¤: {e}")

    # åˆä½µå£“ç¸®çµæœ
    if all_compression_results:
        compression_df = pd.concat(all_compression_results, ignore_index=True)
        compression_path = "/home/adlink/å®‡ç¿°è«–æ–‡/outputs/fair_kitti_compression.csv"
        compression_df.to_csv(compression_path, index=False)

        print(f"\nâœ“ å£“ç¸®å¯¦é©—å®Œæˆ: {len(compression_df)} ç­†è¨˜éŒ„")

        # è¨ˆç®—å¹³å‡å£“ç¸®æ¯”
        avg_compression = compression_df.groupby('Method')['Compression Ratio'].mean()
        print("\nå„æ–¹æ³•å¹³å‡å£“ç¸®æ¯”:")
        for method, ratio in avg_compression.items():
            print(f"  {method}: {ratio:.3f}")

    # 2. TSNç¶²è·¯å¯¦é©—
    print("\n=== éšæ®µ2: TSNç¶²è·¯å¯¦é©— ===")

    tsn_results = []
    tsn_bandwidth_gbps = 1.0
    frame_rate = 10  # Hz

    # å£“ç¸®è™•ç†å»¶é²
    processing_delays = {
        'Huffman': 2.8,
        'EB-HC(Axis)': 3.5,
        'EB-HC(L2)': 4.1,
        'EB-Octree(Axis)': 5.0,
        'EB-Octree(L2)': 5.0,
        'EB-HC-3D(Axis)': 5.2,
        'EB-HC-3D(L2)': 6.1
    }

    # å°æ¯å€‹å ´æ™¯å’Œæ–¹æ³•è¨ˆç®—TSNæ€§èƒ½
    for scene, stats in dataset_stats.items():
        # å¹³å‡æª”æ¡ˆå¤§å°
        avg_file_mb = (stats['size_gb'] * 1024) / stats['files']

        # æœªå£“ç¸®æƒ…æ³
        uncompressed_bitrate = avg_file_mb * 8 * frame_rate
        uncompressed_util = (uncompressed_bitrate / (tsn_bandwidth_gbps * 1000)) * 100
        uncompressed_trans = (avg_file_mb * 8) / (tsn_bandwidth_gbps * 1000)
        uncompressed_latency = 2 + uncompressed_trans + uncompressed_util * 0.05

        tsn_results.append({
            'Scene': scene,
            'Method': 'Uncompressed',
            'File_Size_MB': avg_file_mb,
            'Compression_Ratio': 1.0,
            'Bitrate_Mbps': uncompressed_bitrate,
            'Network_Utilization_%': uncompressed_util,
            'Total_Latency_ms': uncompressed_latency,
            'Feasible': uncompressed_util < 80
        })

        # å£“ç¸®æƒ…æ³
        if compression_df is not None:
            scene_compression = compression_df[compression_df['Scene'] == scene]
            if not scene_compression.empty:
                for method in scene_compression['Method'].unique():
                    method_data = scene_compression[scene_compression['Method'] == method]
                    avg_ratio = method_data['Compression Ratio'].mean()

                    compressed_size_mb = avg_file_mb * avg_ratio
                    compressed_bitrate = compressed_size_mb * 8 * frame_rate
                    compressed_util = (compressed_bitrate / (tsn_bandwidth_gbps * 1000)) * 100
                    compressed_trans = (compressed_size_mb * 8) / (tsn_bandwidth_gbps * 1000)

                    processing = processing_delays.get(method, 5.0)
                    compressed_latency = 2 + processing + compressed_trans + compressed_util * 0.05

                    tsn_results.append({
                        'Scene': scene,
                        'Method': method,
                        'File_Size_MB': compressed_size_mb,
                        'Compression_Ratio': avg_ratio,
                        'Bitrate_Mbps': compressed_bitrate,
                        'Network_Utilization_%': compressed_util,
                        'Processing_Latency_ms': processing,
                        'Total_Latency_ms': compressed_latency,
                        'Feasible': compressed_util < 80
                    })

    tsn_df = pd.DataFrame(tsn_results)
    tsn_path = "/home/adlink/å®‡ç¿°è«–æ–‡/outputs/fair_kitti_tsn.csv"
    tsn_df.to_csv(tsn_path, index=False)

    print(f"âœ“ TSNå¯¦é©—å®Œæˆ: {len(tsn_df)} å€‹é…ç½®")
    print(f"  å¹³å‡å»¶é²: {tsn_df['Total_Latency_ms'].mean():.2f} ms")
    print(f"  å¯è¡Œé…ç½®: {tsn_df['Feasible'].sum()}/{len(tsn_df)}")

    # 3. IPFSå„²å­˜å¯¦é©—
    print("\n=== éšæ®µ3: IPFSå„²å­˜å¯¦é©— ===")

    ipfs_results = []
    upload_speed_mbps = 10
    daily_hours = 12
    annual_frames = frame_rate * 3600 * daily_hours * 365

    for scene, stats in dataset_stats.items():
        original_annual_gb = (annual_frames * stats['size_gb'] / stats['files']) / 1024

        # æœªå£“ç¸®
        ipfs_results.append({
            'Scene': scene,
            'Method': 'Uncompressed',
            'Original_GB': stats['size_gb'],
            'Compressed_GB': stats['size_gb'],
            'Storage_Savings_%': 0,
            'Upload_Time_Hours': (stats['size_gb'] * 1024 * 8) / (upload_speed_mbps * 3600)
        })

        # å£“ç¸®
        if compression_df is not None:
            scene_compression = compression_df[compression_df['Scene'] == scene]
            if not scene_compression.empty:
                for method in scene_compression['Method'].unique():
                    method_data = scene_compression[scene_compression['Method'] == method]
                    avg_ratio = method_data['Compression Ratio'].mean()

                    compressed_gb = stats['size_gb'] * avg_ratio
                    savings = (1 - avg_ratio) * 100
                    upload_time = (compressed_gb * 1024 * 8) / (upload_speed_mbps * 3600)

                    ipfs_results.append({
                        'Scene': scene,
                        'Method': method,
                        'Original_GB': stats['size_gb'],
                        'Compressed_GB': compressed_gb,
                        'Storage_Savings_%': savings,
                        'Upload_Time_Hours': upload_time
                    })

    ipfs_df = pd.DataFrame(ipfs_results)
    ipfs_path = "/home/adlink/å®‡ç¿°è«–æ–‡/outputs/fair_kitti_ipfs.csv"
    ipfs_df.to_csv(ipfs_path, index=False)

    print(f"âœ“ IPFSå¯¦é©—å®Œæˆ: {len(ipfs_df)} å€‹é…ç½®")
    print(f"  å¹³å‡å„²å­˜ç¯€çœ: {ipfs_df[ipfs_df['Method'] != 'Uncompressed']['Storage_Savings_%'].mean():.1f}%")

    # 4. ç”Ÿæˆç¶œåˆå ±å‘Š
    end_time = time.time()
    execution_time = end_time - start_time

    report = {
        'experiment': 'å…¬å¹³KITTIå¯¦é©— - æ‰€æœ‰å ´æ™¯',
        'timestamp': datetime.now().isoformat(),
        'execution_time_seconds': execution_time,
        'dataset': {
            'total_files': total_files,
            'total_size_gb': total_size_gb,
            'scenes': list(dataset_stats.keys())
        },
        'compression': {
            'records': len(compression_df) if 'compression_df' in locals() else 0,
            'best_method': avg_compression.idxmin() if 'avg_compression' in locals() else 'N/A',
            'best_ratio': avg_compression.min() if 'avg_compression' in locals() else 1.0
        },
        'tsn': {
            'configurations': len(tsn_df),
            'avg_latency_ms': tsn_df['Total_Latency_ms'].mean(),
            'min_latency_ms': tsn_df['Total_Latency_ms'].min(),
            'feasibility_rate': (tsn_df['Feasible'].sum() / len(tsn_df)) * 100
        },
        'ipfs': {
            'configurations': len(ipfs_df),
            'avg_storage_savings': ipfs_df[ipfs_df['Method'] != 'Uncompressed']['Storage_Savings_%'].mean()
        }
    }

    report_path = "/home/adlink/å®‡ç¿°è«–æ–‡/outputs/fair_kitti_report.json"
    with open(report_path, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)

    # é¡¯ç¤ºæœ€çµ‚çµæœ
    print("\n" + "="*60)
    print("ğŸ å…¬å¹³å¯¦é©—çµæœæ‘˜è¦")
    print("="*60)

    print(f"\nâœ… å®Œæ•´KITTIæ•¸æ“šé›†: {total_files} æª”æ¡ˆ, {total_size_gb:.2f} GB")
    print(f"âœ… æ¸¬è©¦æ‰€æœ‰5å€‹å ´æ™¯: {', '.join(dataset_stats.keys())}")

    if 'compression_df' in locals():
        print(f"\nå£“ç¸®å¯¦é©—:")
        print(f"  æœ€ä½³æ–¹æ³•: {report['compression']['best_method']}")
        print(f"  æœ€ä½³å£“ç¸®æ¯”: {report['compression']['best_ratio']:.3f}")

    print(f"\nTSNç¶²è·¯å¯¦é©—:")
    print(f"  å¹³å‡å»¶é²: {report['tsn']['avg_latency_ms']:.2f} ms")
    print(f"  æœ€å°å»¶é²: {report['tsn']['min_latency_ms']:.2f} ms")
    print(f"  å¯è¡Œæ€§: {report['tsn']['feasibility_rate']:.1f}%")

    print(f"\nIPFSå„²å­˜å¯¦é©—:")
    print(f"  å¹³å‡ç¯€çœ: {report['ipfs']['avg_storage_savings']:.1f}%")

    print(f"\nåŸ·è¡Œæ™‚é–“: {execution_time:.1f} ç§’")

    print("\nğŸ“ è¼¸å‡ºæª”æ¡ˆ:")
    print("  â€¢ fair_kitti_compression.csv")
    print("  â€¢ fair_kitti_tsn.csv")
    print("  â€¢ fair_kitti_ipfs.csv")
    print("  â€¢ fair_kitti_report.json")

    return report

if __name__ == "__main__":
    result = run_fair_experiment()
    print("\nâœ… å…¬å¹³å¯¦é©—å®Œæˆï¼æ‰€æœ‰å ´æ™¯éƒ½å·²æ¸¬è©¦ï¼Œçµæœä»£è¡¨æ•´å€‹æ•¸æ“šé›†ã€‚")